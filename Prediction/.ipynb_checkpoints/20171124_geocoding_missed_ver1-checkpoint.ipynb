{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo Coding (緯度経度取得)・最寄駅情報取得を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 脱漏の補充_0~2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../gci_project_storage/result_list_missed.pickle', mode='rb') as f:\n",
    "    addresses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_list_to_2000_missed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serviceurl = 'http://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "\n",
    "for address in addresses[:2000]:\n",
    "    time_to_wait = 10\n",
    "    while if_NG==True:\n",
    "        url = serviceurl + urllib.parse.urlencode({u'sensor':u'false', u'address': address})\n",
    "        uh = urllib.request.urlopen(url)\n",
    "        data = uh.read()\n",
    "        tree = ET.fromstring(data)\n",
    "        if_NG = tree.findall(\"status\")[0].text!='OK'\n",
    "        if if_NG:\n",
    "            time_to_wait += 30\n",
    "            time.sleep(time_to_wait)\n",
    "    results = tree.findall('result')\n",
    "    result_list_to_2000_missed.append(data)\n",
    "    time.sleep(10)\n",
    "    if_NG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list_to_2000_missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../gci_project_storage/result_list_to_2000_missed.pickle', mode='wb') as f:\n",
    "    pickle.dump(result_list_to_2000_missed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../gci_project_storage/result_list_to_2000_missed.pickle', mode='rb') as f:\n",
    "    result_list_to_2000_missed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loc_json = lambda data: ET.fromstring(data).findall('result')[0].find('geometry').find('location') if len(ET.fromstring(data).findall('result'))>0 else None \n",
    "get_lat = lambda data: float(get_loc_json(data).find('lat').text) if get_loc_json(data) != None else None\n",
    "get_lng = lambda data: float(get_loc_json(data).find('lng').text) if get_loc_json(data) != None else None\n",
    "\n",
    "import math\n",
    "sum(pd.Series([get_lat(data) for data in result_list_to_2000_missed]).apply(math.isnan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 脱漏の補充_2000~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('result_list_missed.pickle', mode='rb') as f:\n",
    "    addresses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_list_from_2000_missed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceurl = 'http://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "if_NG = True\n",
    "\n",
    "for address in addresses[2000:]:\n",
    "    time_to_wait = 10\n",
    "    while if_NG==True:\n",
    "        url = serviceurl + urllib.parse.urlencode({u'sensor':u'false', u'address': address})\n",
    "        uh = urllib.request.urlopen(url)\n",
    "        data = uh.read()\n",
    "        tree = ET.fromstring(data)\n",
    "        if_NG = tree.findall(\"status\")[0].text!='OK'\n",
    "        if if_NG:\n",
    "            time_to_wait += 30\n",
    "            time.sleep(time_to_wait)\n",
    "    results = tree.findall('result')\n",
    "    result_list_from_2000_missed.append(data)\n",
    "    time.sleep(10)\n",
    "    if_NG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../gci_project_storage/result_list_from_2000_missed.pickle', mode='wb') as f:\n",
    "    pickle.dump(result_list_from_2000_missed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../gci_project_storage/result_list_from_2000_missed.pickle', mode='rb') as f:\n",
    "    result_list_from_2000_missed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loc_json = lambda data: ET.fromstring(data).findall('result')[0].find('geometry').find('location') if len(ET.fromstring(data).findall('result'))>0 else None \n",
    "get_lat = lambda data: float(get_loc_json(data).find('lat').text) if get_loc_json(data) != None else None\n",
    "get_lng = lambda data: float(get_loc_json(data).find('lng').text) if get_loc_json(data) != None else None\n",
    "\n",
    "import math\n",
    "sum(pd.Series([get_lat(data) for data in result_list_from_2000_missed]).apply(math.isnan))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
